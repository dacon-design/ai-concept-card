import { NextResponse } from "next/server";
import OpenAI from "openai";

export async function POST(req: Request) {
  const { concept } = await req.json();

  if (!concept) {
    return NextResponse.json({ error: "Concept is required" }, { status: 400 });
  }

  const apiKey = process.env.OPENAI_API_KEY;
  const baseUrl = process.env.OPENAI_BASE_URL;

  // Mock response if no API key is present or for testing
  if (!apiKey) {
    console.log("No API key found, returning mock response");
    await new Promise((resolve) => setTimeout(resolve, 2000)); // Simulate delay
    return NextResponse.json({
      title: concept,
      subtitle: "Mock Generated Concept",
      description: `This is a mock explanation for "${concept}". A real explanation would be generated by AI, describing the concept in depth, its origins, and its significance in a clear and concise manner. To enable real generation, please provide an OPENAI_API_KEY in your environment variables.`,
      imageUrl: "https://images.unsplash.com/photo-1635070041078-e363dbe005cb?q=80&w=3270&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    });
  }

  try {
    console.log("Initializing OpenAI client with API key...");
    const openai = new OpenAI({ 
      apiKey,
      baseURL: baseUrl || undefined
    });

    const llmModel = process.env.LLM_MODEL || "gpt-3.5-turbo";
    const imageModel = process.env.IMAGE_MODEL || "dall-e-3";

    // Log masked API key for debugging
    if (apiKey) {
      console.log(`API Key loaded: ${apiKey.substring(0, 5)}...${apiKey.substring(apiKey.length - 4)}`);
    } else {
      console.error("API Key is missing!");
    }

    console.log("Generating text for concept:", concept);
    // 1. Generate text explanation
    const textCompletion = await openai.chat.completions.create({
      model: llmModel,
      messages: [
        {
          role: "system",
          content: "You are a helpful assistant that explains concepts clearly and concisely. You MUST return a valid JSON object. Do not include markdown formatting (like ```json). The JSON object must have these keys: title (keep original language), subtitle (English translation), description (around 300 words in Chinese, explaining the concept in depth with examples, significance, and poetic language), and imagePrompt (a detailed English description for DALL-E to generate a minimal, abstract, or symbolic image representing this concept)."
        },
        {
          role: "user",
          content: `Explain the concept: "${concept}"`
        }
      ],
    });

    console.log("Text generation successful");
    let content = textCompletion.choices[0].message.content || "{}";
    // Clean up markdown formatting if present
    content = content.replace(/```json\n?|\n?```/g, "").trim();
    
    console.log("Parsed content:", content);
    const textResponse = JSON.parse(content);

    console.log("Generating image with prompt:", textResponse.imagePrompt);
    // 2. Generate image
    let imageUrl = "https://images.unsplash.com/photo-1635070041078-e363dbe005cb?q=80&w=3270&auto=format&fit=crop&ixlib=rb-4.0.3"; // Fallback image
    
    try {
      console.log("Generating image with Zhipu AI (CogView)...");
      
      const zhipu = new OpenAI({
        apiKey: process.env.ZHIPU_API_KEY,
        baseURL: "https://open.bigmodel.cn/api/paas/v4/"
      });

      const response = await zhipu.images.generate({
        model: "cogview-3",
        prompt: textResponse.imagePrompt || `A minimal, abstract representation of ${concept}`,
      });
      
      if (response.data?.[0]?.url) {
        console.log("Zhipu image generation successful");
        const tempUrl = response.data[0].url;

        
        // Proxy the image: Download and convert to Base64 to avoid CORS issues in frontend (html2canvas)
        try {
            console.log("Fetching image to convert to base64...");
            const imgRes = await fetch(tempUrl);
            if (!imgRes.ok) throw new Error(`Failed to fetch image: ${imgRes.statusText}`);
            const imgBuffer = await imgRes.arrayBuffer();
            const base64Image = Buffer.from(imgBuffer).toString('base64');
            imageUrl = `data:image/png;base64,${base64Image}`;
            console.log("Image converted to base64 successfully");
        } catch (fetchErr) {
            console.error("Failed to proxy image:", fetchErr);
            // Fallback to original URL if proxy fails (though this might cause CORS issues)
            imageUrl = tempUrl;
        }
      } else {
        console.error("Zhipu image generation failed:", JSON.stringify(response));
      }
    } catch (imgError: any) {
      console.error("Image generation failed:", imgError.message);
    }

    return NextResponse.json({
      title: textResponse.title || concept,
      subtitle: textResponse.subtitle,
      description: textResponse.description,
      imageUrl: imageUrl
    });

  } catch (error: any) {
    console.error("Error generating concept card:", error);
    return NextResponse.json({ 
      error: error.message || "Failed to generate content",
      details: error.toString() 
    }, { status: 500 });
  }
}
