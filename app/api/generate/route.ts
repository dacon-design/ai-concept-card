import { NextResponse } from "next/server";
import OpenAI from "openai";

export async function POST(req: Request) {
  const { concept } = await req.json();

  if (!concept) {
    return NextResponse.json({ error: "Concept is required" }, { status: 400 });
  }

  const apiKey = process.env.OPENAI_API_KEY;
  const baseUrl = process.env.OPENAI_BASE_URL;

  // Mock response if no API key is present or for testing
  if (!apiKey) {
    console.log("No API key found, returning mock response");
    await new Promise((resolve) => setTimeout(resolve, 2000)); // Simulate delay
    return NextResponse.json({
      title: concept,
      subtitle: "Mock Generated Concept",
      description: `This is a mock explanation for "${concept}". A real explanation would be generated by AI, describing the concept in depth, its origins, and its significance in a clear and concise manner. To enable real generation, please provide an OPENAI_API_KEY in your environment variables.`,
      imageUrl: "https://images.unsplash.com/photo-1635070041078-e363dbe005cb?q=80&w=3270&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"
    });
  }

  try {
    console.log("Initializing OpenAI client with API key...");
    const openai = new OpenAI({ 
      apiKey,
      baseURL: baseUrl || undefined
    });

    const llmModel = process.env.LLM_MODEL || "gpt-3.5-turbo";
    const imageModel = process.env.IMAGE_MODEL || "dall-e-3";

    // Log masked API key for debugging
    if (apiKey) {
      console.log(`API Key loaded: ${apiKey.substring(0, 5)}...${apiKey.substring(apiKey.length - 4)}`);
    } else {
      console.error("API Key is missing!");
    }

    console.log("Generating text and image prompt in parallel for concept:", concept);
    
    // 1. Define the text generation task
    const textGenerationPromise = openai.chat.completions.create({
      model: llmModel,
      messages: [
        {
          role: "system",
          content: "You are a helpful assistant that explains concepts clearly and concisely. You MUST return a valid JSON object. Do not include markdown formatting (like ```json). The JSON object must have these keys: title (keep original language), subtitle (English translation), description (MUST BE in Simplified Chinese, around 200 words, explaining the concept deeply, focusing on its core essence, significance, and philosophical depth. Use poetic, elegant, and direct language)."
        },
        {
          role: "user",
          content: `Explain the concept: "${concept}"`
        }
      ],
    }).then(completion => {
      let content = completion.choices[0].message.content || "{}";
      content = content.replace(/```json\n?|\n?```/g, "").trim();
      return JSON.parse(content);
    });

    // 2. Define the image prompt generation task
    const imagePromptPromise = openai.chat.completions.create({
      model: llmModel,
      messages: [
        {
          role: "system",
          content: "You are an expert prompt engineer. Generate a detailed English description for an AI image generator to create a minimal, abstract, or symbolic image representing the user's concept. The style should be high-end, artistic, and suitable for a concept card background. Return ONLY the prompt string, nothing else."
        },
        {
          role: "user",
          content: `Concept: "${concept}"`
        }
      ],
    }).then(completion => completion.choices[0].message.content || `A minimal, abstract representation of ${concept}`);

    // 3. Start image generation as soon as the prompt is ready
    const imageGenerationPromise = imagePromptPromise.then(async (imagePrompt) => {
        console.log("Image prompt generated:", imagePrompt);
        let finalImageUrl = "https://images.unsplash.com/photo-1635070041078-e363dbe005cb?q=80&w=3270&auto=format&fit=crop&ixlib=rb-4.0.3"; // Fallback

        try {
            console.log("Generating image with Zhipu AI (CogView-3-Flash)...");
            
            const zhipu = new OpenAI({
                apiKey: process.env.ZHIPU_API_KEY,
                baseURL: "https://open.bigmodel.cn/api/paas/v4/"
            });

            const response = await zhipu.images.generate({
                model: "cogview-3-flash", // Using Flash model for speed
                prompt: imagePrompt,
            });
            
            if (response.data?.[0]?.url) {
                console.log("Zhipu image generation successful");
                const tempUrl = response.data[0].url;

                // Proxy the image
                try {
                    console.log("Fetching image to convert to base64...");
                    const imgRes = await fetch(tempUrl);
                    if (!imgRes.ok) throw new Error(`Failed to fetch image: ${imgRes.statusText}`);
                    const imgBuffer = await imgRes.arrayBuffer();
                    const base64Image = Buffer.from(imgBuffer).toString('base64');
                    finalImageUrl = `data:image/png;base64,${base64Image}`;
                    console.log("Image converted to base64 successfully");
                } catch (fetchErr) {
                    console.error("Failed to proxy image:", fetchErr);
                    finalImageUrl = tempUrl;
                }
            } else {
                console.error("Zhipu image generation failed:", JSON.stringify(response));
            }
        } catch (imgError: any) {
            console.error("Image generation failed:", imgError.message);
        }
        return finalImageUrl;
    });

    // 4. Wait for both text and image generation to complete
    const [textResponse, imageUrl] = await Promise.all([textGenerationPromise, imageGenerationPromise]);

    console.log("All generation tasks completed");

    return NextResponse.json({
      title: textResponse.title || concept,
      subtitle: textResponse.subtitle,
      description: textResponse.description,
      imageUrl: imageUrl
    });

  } catch (error: any) {
    console.error("Error generating concept card:", error);
    return NextResponse.json({ 
      error: error.message || "Failed to generate content",
      details: error.toString() 
    }, { status: 500 });
  }
}
